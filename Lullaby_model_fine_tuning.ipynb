{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lullaby_model_fine-tuning.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "E1igB_iCIY5t",
        "hzGpNjKzmtQD",
        "wbKp7JFgUm1i",
        "b5FT5t9bm4ud",
        "U2zVVst0nRFk"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uyPVE4ADaFoC"
      },
      "source": [
        "# Model fine-tuning\n",
        "Fine-tuning of a GPT-2 small Spanish model to generate lullabies or \"nanas\".\n",
        "\n",
        "We have used this notebook as reference\n",
        "https://colab.research.google.com/drive/13dZVYEOMhXhkXWfvSMVM1TTtUDrT6Aeh?usp=sharing#scrollTo=NKGBoVwuhM4H but with an spanish model ([datificate/gpt2-small-spanish](https://huggingface.co/datificate/gpt2-small-spanish))."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E1igB_iCIY5t"
      },
      "source": [
        "## Setup\n",
        "Install dependencies and import libraries needed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qjGY-siIRKxw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8408583-d54b-4304-fd2b-7e5306b4c81a"
      },
      "source": [
        "# Check Transformers Library from HuggingFace\n",
        "! pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d8/b2/57495b5309f09fa501866e225c84532d1fd89536ea62406b2181933fb418/transformers-4.5.1-py3-none-any.whl (2.1MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1MB 16.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |████████████████████████████████| 901kB 53.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.10.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/04/5b870f26a858552025a62f1649c20d29d2672c02ff3c3fb4c688ca46467a/tokenizers-0.10.2-cp37-cp37m-manylinux2010_x86_64.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 55.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Installing collected packages: sacremoses, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.45 tokenizers-0.10.2 transformers-4.5.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RjdZ73r5RZDV"
      },
      "source": [
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "import datetime\n",
        "import time\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModelWithLMHead, AdamW, get_linear_schedule_with_warmup"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hB0uF4hjmRq5"
      },
      "source": [
        "## GPT-2 (spanish) fine-tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hzGpNjKzmtQD"
      },
      "source": [
        "### Data loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jL0ZSLyKRkje"
      },
      "source": [
        "data_list = [\n",
        "\"\"\"Duérmete, niñito mío,\n",
        "que tu madre no está en casa;\n",
        "que se la llevó la Virgen\n",
        "de compañera a su casa.\"\"\",\n",
        "\"\"\"Duérmete, niño chico,\n",
        "duérmete, mi bien;\n",
        "que aquí está la cunita\n",
        "que te ha de mecer.\"\"\",\n",
        "\"\"\"Duérmete, vida mía,\n",
        "duerme sin pena,\n",
        "porque al pie de la cuna\n",
        "tu madre vela.\"\"\",\n",
        "\"\"\"Duerme, niño mío,\n",
        "que tengo que hacer,\n",
        "me han traído el trigo\n",
        "y está por moler.\"\"\",\n",
        "\"\"\"Duérmete, niño de cuna,\n",
        "duérmete, niño de amor,\n",
        "que a los pies tienes la luna\n",
        "y a la cabecera el sol.\"\"\",\n",
        "\"\"\"Duérmete, mi niño,\n",
        "que viene el coco\n",
        "y se lleva a los niños\n",
        "que duermen poco.\"\"\",\n",
        "\"\"\"Duérmete, niño,\n",
        "duérmete ya\n",
        "que viene el coco\n",
        "y te comerá.\"\"\",\n",
        "\"\"\"Este galapaguito no tiene mare.\n",
        "lo parió una gitana,\n",
        "lo echó a la calle.\n",
        "Este niño chiquito\n",
        "no tiene cuna.\n",
        "Su padre es carpintero\n",
        "y le hará una cuna.\n",
        "Y le hace una de caramelo\n",
        "para que cuando despierte\n",
        "se chupe el dedo\"\"\",\n",
        "\"\"\"Al sueño le crecen\t\t\n",
        "cabellos de yerba.\t\t\n",
        "Al sueño le nacen azules gacelas,\t\t\n",
        "que muerden los prados,\t\t\n",
        "que triscan las eras;\t\t\n",
        "que pacen las noches\t\t\n",
        "sin que el sueño pueda\t\t\n",
        "cortarse sus ramas\t\n",
        "de verdes almendras.\"\"\"\n",
        "\"\"\"Al sueño le llaman\t\t\n",
        "y el sueño contesta,\t\t\n",
        "con sus ojos claros\t\t\n",
        "y su boca lenta,\t\t\n",
        "que dice palabras\t\t\n",
        "que el sueño se inventa.\t\t\n",
        "Duérmete, mi vida,\t\t\n",
        "niña de la tierra:\t\t\n",
        "que el sueño te canta\t\t\n",
        "para que te duermas.\"\"\",\n",
        "\"\"\"Duérmete, niño chico,\t\t\n",
        "duérmete, mi bien;\t\t\n",
        "que aquí está la cunita\t\t\n",
        "que te ha de mecer.\"\"\",\n",
        "\"\"\"En los brazos te tengo\t\t\n",
        "y considero\t\t\n",
        "qué será de ti, niño,\t\t\n",
        "si yo me muero.\"\"\",\n",
        "\"\"\"Duerme, niño chiquito,\t\t\n",
        "duérmete y calla;\t\t\n",
        "no le des a tu madre\t\t\n",
        "tanta batalla.\"\"\",\n",
        "\"\"\"Este niño tiene sueño,\t\t\n",
        "no tiene cama ni cuna.\t\t\n",
        "A su padre carpintero\t\t\n",
        "le diremos le haga una .\"\"\",\n",
        "\"\"\"Si este niño se durmiera,\t\t\n",
        "yo le diera medio real,\t\t\n",
        "para que se comprara\t\t\n",
        "un pedacito de pan.\"\"\",\n",
        "\"\"\"Duérmete, niño,\t\t\n",
        "que ahí viene el coco,\t\t\n",
        "y se lleva a los niños\t\t\n",
        "que duermen poco.\"\"\",\n",
        "\"\"\"Duérmete mi niño\t\t\n",
        "y duérmete ya,\t\t\n",
        "porque viene el coco\t\t\n",
        "y te comerá.\"\"\",\n",
        "\"\"\"Con decirle a mi niño\t\t\n",
        "que viene el coco,\t\t\n",
        "le va perdiendo el miedo\t\t\n",
        "poquito a poco.\"\"\",\n",
        "\"\"\"Las mujeres de la sierra,\t\t\n",
        "para dormir a sus niños,\t\t\n",
        "en vez de llamar al coco\t\t\n",
        "les cantan un fandanguillo.\"\"\",\n",
        "\"\"\"Y arrorró, canelica,\t\t\n",
        "que viene el coco\t\t\n",
        "y se lleva a los nenes\t\t\n",
        "que duermen poco.\t\t\n",
        "Mi chico se va a dormir\t\t\n",
        "porque tiene mucho sueño,\t\t\n",
        "y por cabecera tiene\t\t\n",
        "a la Virgen del Remedio.\"\"\",\n",
        "\"\"\"Original persona pequeñita\t\t\n",
        "que al contrario de todos\t\t\n",
        "no has nacido.\t\t\n",
        "Vívete, niño, vívete,\t\t\n",
        "que viene el Coco\t\t\n",
        "y se lleva a los niños\t\t\n",
        "que duermen poco.\"\"\"\t\t\n",
        "\"\"\"Late un momento rey\t\t\n",
        "-la madre dice-,\t\t\n",
        "deja que me dé tiempo\t\t\n",
        "a que te bautice.\t\t\n",
        "Te iba a poner Tomás,\t\t\n",
        "y ya te vas.\t\t\n",
        "Para qué habrás venido\t\t\n",
        "sin más ni más.\t\n",
        "Qué frío tienes, hijo,\t\t\n",
        "sin un temblor,\t\t\n",
        "creo que dentro estabas\t\t\n",
        "mucho mejor.\"\"\"\n",
        "\"\"\"-En el lago de llanto\t\t\n",
        "de tu madre\t\t\n",
        "jugabas en la orilla…\n",
        "- Que el demonio se lleve\n",
        "tu canastilla\n",
        "-Tiene ojos de listo,\n",
        "es un pequeño sabio.\n",
        "Y otra vecina dijo:\t\n",
        "-De buena se ha librado.\"\"\"\t\n",
        "\"\"\"Pequeño criminal,\t\t\n",
        "dulce adversario\t\t\n",
        "-sin nacer ni morir\t\t\n",
        "a tu madre has matado-,\t\t\n",
        "mientras tú,\t\t\n",
        "mi niño diferente,\t\t\n",
        "ni blanco ni negro,\t\t\n",
        "mientras tú…\t\t\n",
        "Échate un sueño largo,\t\t\n",
        "mi niño azul.\"\"\",\n",
        "\"\"\"A la mar, si no duermes,\t\t\n",
        "que viene el viento.\t\t\n",
        "Ya en las grutas marinas\t\t\n",
        "ladran sus perros.\t\t\n",
        "Si no duermes, al monte.\t\t\n",
        "Vienen el búho\t\t\n",
        "y el gavilán del bosque.\t\t\n",
        "Cuando te duermas:\t\t\n",
        "al almendro, mi niño,\t\t\n",
        "y a la estrella de menta.\"\"\",\n",
        "\"\"\"Duérmete, niñito,\t\t\n",
        "duérmete, por Dios,\t\t\n",
        "si no viene el brujo\t\t\n",
        "y te va a comer.\"\"\",\n",
        "\"\"\"Con un traje rico\t\t\n",
        "y su hijito feo,\t\t\n",
        "la loba, la loba,\t\t\n",
        "vendrá por aquí,\t\t\n",
        "si esta niña linda\t\t\n",
        "no quiere dormir.\"\"\",\n",
        "\"\"\"Duérmete, guagüita,\t\t\n",
        "que viene la cierva\t\t\n",
        "a saltos y brincos\t\t\n",
        "por entre las piedras.\"\"\",\n",
        "\"\"\"Dúermete, niñito,\t\t\n",
        "cabeza de ayote;\t\t\n",
        "si no te dormís,\t\t\n",
        "te come el coyote.\"\"\",\n",
        "\"\"\"Duérmete, niño chiquito,\t\t\n",
        "duérmete y no llores más,\t\t\n",
        "que se irán los angelitos\t\t\n",
        "para no verte llorar.\"\"\",\n",
        "\"\"\"A los niños buenos\t\t\n",
        "Dios los bendice;\t\t\n",
        "a los que son malos\t\t\n",
        "les da lombrices.\"\"\",\n",
        "\"\"\"Duérmete mi negrazo,\t\t\n",
        "cara de pambazo,\t\t\n",
        "que si no se duerme\t\t\n",
        "le doy un trancazo.\"\"\",\n",
        "\"\"\"En los brazos te tengo\t\t\n",
        "y considero\t\t\n",
        "qué será de ti, niño,\t\t\n",
        "si yo me muero.\"\"\",\n",
        "\"\"\"Duérmete, niño, en la cuna\n",
        "que viene la reina mora\n",
        "preguntando por las casas\n",
        "quién es el niño que llora.\"\"\",\n",
        "\"\"\"Duérmete, niño chiquito,\n",
        "mira que viene la mora\n",
        "preguntando puerta en puerta\n",
        "cuál es el niño que llora.\"\"\",\n",
        "\"\"\"Vete ya, lobo malo,\n",
        "que el nene duerme.\n",
        "Márchate despacito,\n",
        "no se despierte.\"\"\",\n",
        "\"\"\"Milano negro que vuelas\n",
        "sobre el techo de mi casa.\n",
        "¡Vete, milano! que al niño\n",
        "le estoy cantando una nana.\"\"\",\n",
        "\"\"\"Angelitos del cielo\n",
        "venir cantando\n",
        "y llevarse a este niño,\n",
        "que está llorando.\"\"\",\n",
        "\"\"\"Si este niño no se duerme,\n",
        "Venga un ángel y lo lleve.\n",
        "–No vengas, angelito, no,\n",
        "que este niño se durmió.\"\"\",\n",
        "\"\"\"Caballero en la jaca con alas\n",
        "se vino y le lleva\n",
        "montado a la grupa,\n",
        "se vino y le lleva\n",
        "volando, volando, volando\n",
        "mi niño… mi prenda.\"\"\",\n",
        "\"\"\"Este niño no puede dormir.\n",
        "El coquito no le deja,\n",
        "que le tiene agarradito\n",
        "de los pies a la cabeza.\"\"\",\n",
        "\"\"\"Sabes tú, niño,\n",
        "que quiere el coco:\n",
        "que tengas miedo,\n",
        "ni mucho ni poco.\"\"\",\n",
        "\"\"\"Duérmete, mi niño,\n",
        "duérmete sin miedo,\n",
        "aunque silben los aires,\n",
        "gruñan los perros.\"\"\",\n",
        "\"\"\"Ya no dicen las madres\n",
        "Que viene el coco;\n",
        "Que esta voz a los niños\n",
        "Asusta poco.\n",
        "Si el caso apura,\n",
        "Le dicen: Calla, niño,\n",
        "Que viene el cura\"\"\",\n",
        "\"\"\"Las mujeres de la sierra\n",
        "para dormir los chiquillos\n",
        "en vez de cantar el coco\n",
        "le arrean con un ladrillo\n",
        "y le duermen poco a poco.\"\"\"\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5YHtGQd6Yxx",
        "outputId": "f33761f0-a142-423a-fab6-ea51c4598505"
      },
      "source": [
        "print(\"Total number of lullabies: \", len(data_list))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total number of lullabies:  41\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wbKp7JFgUm1i"
      },
      "source": [
        "### GPT-2 small spanish model loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HYaKXgvpRfHs",
        "outputId": "5a45106f-c7ca-4156-ae5f-40dbb10ba831"
      },
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"datificate/gpt2-small-spanish\")\n",
        "\n",
        "model = AutoModelWithLMHead.from_pretrained(\"datificate/gpt2-small-spanish\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/models/auto/modeling_auto.py:762: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YnVvJkIhRn7Z",
        "outputId": "536c480f-2257-4a19-e278-6d34574cb6fb"
      },
      "source": [
        "print(\"The max model length is {} for this model, although the actual embedding size for GPT small is 768\".format(tokenizer.model_max_length))\n",
        "print(\"The beginning of sequence token {} token has the id {}\".format(tokenizer.convert_ids_to_tokens(tokenizer.bos_token_id), tokenizer.bos_token_id))\n",
        "print(\"The end of sequence token {} has the id {}\".format(tokenizer.convert_ids_to_tokens(tokenizer.eos_token_id), tokenizer.eos_token_id))\n",
        "print(\"The padding token {} has the id {}\".format(tokenizer.convert_ids_to_tokens(tokenizer.pad_token_id), tokenizer.pad_token_id))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The max model length is 1000000000000000019884624838656 for this model, although the actual embedding size for GPT small is 768\n",
            "The beginning of sequence token <|endoftext|> token has the id 0\n",
            "The end of sequence token <|endoftext|> has the id 0\n",
            "The padding token <|endoftext|> has the id 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "esHkNz4fSbws"
      },
      "source": [
        "batch_size = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wyCHOfDUS7Bb"
      },
      "source": [
        "class GPT2Dataset(torch.utils.data.Dataset):\n",
        "\n",
        "  def __init__(self, txt_list, tokenizer, gpt2_type=\"gpt2\", max_length=768):\n",
        "\n",
        "    self.tokenizer = tokenizer\n",
        "    self.input_ids = []\n",
        "    self.attn_masks = []\n",
        "\n",
        "    for txt in txt_list:\n",
        "\n",
        "      encodings_dict = tokenizer('<|endoftext|>' + txt + '<|endoftext|>', truncation=True, max_length=max_length, padding=\"max_length\")\n",
        "\n",
        "      self.input_ids.append(torch.tensor(encodings_dict['input_ids']))\n",
        "      self.attn_masks.append(torch.tensor(encodings_dict['attention_mask']))\n",
        "    \n",
        "  def __len__(self):\n",
        "    return len(self.input_ids)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.input_ids[idx], self.attn_masks[idx] "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YAzQ3rUKT4UK",
        "outputId": "c6f57905-a7f3-4e8b-a2c5-11a1b6ca6d6a"
      },
      "source": [
        "dataset = GPT2Dataset(data_list, tokenizer, max_length=768)\n",
        "\n",
        "# Split into training and validation sets\n",
        "train_size = int(0.95 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "\n",
        "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
        "\n",
        "print('{:>5,} training samples'.format(train_size))\n",
        "print('{:>5,} validation samples'.format(val_size))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   38 training samples\n",
            "    3 validation samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7YIX8pIU3Z2"
      },
      "source": [
        "train_dataloader = torch.utils.data.DataLoader(\n",
        "            train_dataset,  # The training samples.\n",
        "            sampler = torch.utils.data.RandomSampler(train_dataset), # Select batches randomly\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
        "validation_dataloader = torch.utils.data.DataLoader(\n",
        "            val_dataset, # The validation samples.\n",
        "            sampler = torch.utils.data.SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5FT5t9bm4ud"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hsA6PK8xVqqG",
        "outputId": "ad8b3ba8-4aad-4343-ca54-ac1cbe953786"
      },
      "source": [
        "! nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sat May  8 03:45:44 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   48C    P0    28W /  70W |   5952MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VQzZ-i_pV4cg",
        "outputId": "f2c66db8-aa46-4fcd-a018-63780c8c2bb3"
      },
      "source": [
        "# Select device\n",
        "if (torch.cuda.is_available()):\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(\"Running on GPU\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"Running on CPU\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running on GPU\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-J1rJXbWVSZ"
      },
      "source": [
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NfieqOtDWekO"
      },
      "source": [
        "# some parameters that work reasonably well\n",
        "epochs = 40\n",
        "learning_rate = 5e-4\n",
        "warmup_steps = 2\n",
        "epsilon = 1e-8\n",
        "\n",
        "# this produces sample output every 10 steps\n",
        "sample_every = 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5T6t1wvWr8W"
      },
      "source": [
        "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = learning_rate,\n",
        "                  eps = epsilon\n",
        "                )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6QT4079Wziz"
      },
      "source": [
        "# Total number of training steps is [number of batches] x [number of epochs]. \n",
        "# (Note that this is not the same as the number of training samples).\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "# This changes the learning rate as the training loop progresses\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = warmup_steps, \n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ciIlaOZ_XbKa"
      },
      "source": [
        "def format_time(elapsed):\n",
        "    return str(datetime.timedelta(seconds=int(round((elapsed)))))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-FCGdfx5XdVA",
        "outputId": "b1807704-8612-45b7-9fbb-1c576533083f"
      },
      "source": [
        "total_t0 = time.time()\n",
        "\n",
        "training_stats = []\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "for epoch_i in range(0, epochs):\n",
        "\n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    total_train_loss = 0\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_labels = batch[0].to(device)\n",
        "        b_masks = batch[1].to(device)\n",
        "\n",
        "        model.zero_grad()        \n",
        "\n",
        "        outputs = model(  b_input_ids,\n",
        "                          labels=b_labels, \n",
        "                          attention_mask = b_masks,\n",
        "                          token_type_ids=None\n",
        "                        )\n",
        "\n",
        "        loss = outputs[0]  \n",
        "\n",
        "        batch_loss = loss.item()\n",
        "        total_train_loss += batch_loss\n",
        "\n",
        "        # Get sample every x batches.\n",
        "        if step % sample_every == 0 and not step == 0:\n",
        "\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            print('  Batch {:>5,}  of  {:>5,}. Loss: {:>5,}.   Elapsed: {:}.'.format(step, len(train_dataloader), batch_loss, elapsed))\n",
        "\n",
        "            model.eval()\n",
        "\n",
        "            sample_outputs = model.generate(\n",
        "                                    bos_token_id=random.randint(1,30000),\n",
        "                                    do_sample=True,   \n",
        "                                    top_k=50, \n",
        "                                    max_length = 30,\n",
        "                                    top_p=0.95, \n",
        "                                    num_return_sequences=1\n",
        "                                )\n",
        "            for i, sample_output in enumerate(sample_outputs):\n",
        "                  print(\"{}: {}\".format(i, tokenizer.decode(sample_output, skip_special_tokens=True)))\n",
        "            \n",
        "            model.train()\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)       \n",
        "    \n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epoch took: {:}\".format(training_time))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_labels = batch[0].to(device)\n",
        "        b_masks = batch[1].to(device)\n",
        "        \n",
        "        with torch.no_grad():        \n",
        "\n",
        "            outputs  = model(b_input_ids, \n",
        "#                            token_type_ids=None, \n",
        "                             attention_mask = b_masks,\n",
        "                            labels=b_labels)\n",
        "          \n",
        "            loss = outputs[0]  \n",
        "            \n",
        "        batch_loss = loss.item()\n",
        "        total_eval_loss += batch_loss        \n",
        "\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "    \n",
        "    validation_time = format_time(time.time() - t0)    \n",
        "\n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 40 ========\n",
            "Training...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch    10  of     38. Loss: 0.7960211634635925.   Elapsed: 0:00:03.\n",
            "0:  máximas La\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch    20  of     38. Loss: 1.0165116786956787.   Elapsed: 0:00:06.\n",
            "0: ensión,\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch    30  of     38. Loss: 0.49555540084838867.   Elapsed: 0:00:09.\n",
            "0: jae\n",
            "\n",
            "  Average training loss: 2.14\n",
            "  Training epoch took: 0:00:11\n",
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 0.39\n",
            "  Validation took: 0:00:00\n",
            "\n",
            "======== Epoch 2 / 40 ========\n",
            "Training...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch    10  of     38. Loss: 0.4079561233520508.   Elapsed: 0:00:03.\n",
            "0:  descritas la\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch    20  of     38. Loss: 0.460431307554245.   Elapsed: 0:00:06.\n",
            "0:  1900 del, no.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch    30  of     38. Loss: 0.31803303956985474.   Elapsed: 0:00:09.\n",
            "0:  instru de de, las deque,\n",
            "\n",
            "  Average training loss: 0.53\n",
            "  Training epoch took: 0:00:11\n",
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 0.33\n",
            "  Validation took: 0:00:00\n",
            "\n",
            "======== Epoch 3 / 40 ========\n",
            "Training...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch    10  of     38. Loss: 0.41703087091445923.   Elapsed: 0:00:03.\n",
            "0:  definitivamente. niño\n",
            " sedu...\n",
            "\n",
            "y la le tu\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch    20  of     38. Loss: 0.3059452772140503.   Elapsed: 0:00:06.\n",
            "0:  austr yque\n",
            " la\n",
            "ñ\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch    30  of     38. Loss: 0.168169304728508.   Elapsed: 0:00:09.\n",
            "0:  mundialmente laque,\n",
            "te a-\n",
            ". que.queque tu.y. niño\n",
            "\n",
            "  Average training loss: 0.39\n",
            "  Training epoch took: 0:00:12\n",
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 0.27\n",
            "  Validation took: 0:00:00\n",
            "\n",
            "======== Epoch 4 / 40 ========\n",
            "Training...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch    10  of     38. Loss: 0.17536838352680206.   Elapsed: 0:00:03.\n",
            "0:  Ed que\n",
            "\n",
            "ñ.\n",
            "que el,te los. a.que. de ni\n",
            " la untey\n",
            "\n",
            "que\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch    20  of     38. Loss: 0.3848901689052582.   Elapsed: 0:00:06.\n",
            "0:  pensión de\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch    30  of     38. Loss: 0.21349629759788513.   Elapsed: 0:00:09.\n",
            "0:  conducen el\n",
            "Que laY,\n",
            ".\n",
            " el lame niñoque\n",
            "\n",
            " niño coco el ely adu no los. el\n",
            "\n",
            "  Average training loss: 0.36\n",
            "  Training epoch took: 0:00:12\n",
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 0.26\n",
            "  Validation took: 0:00:00\n",
            "\n",
            "======== Epoch 5 / 40 ========\n",
            "Training...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch    10  of     38. Loss: 0.24190697073936462.   Elapsed: 0:00:03.\n",
            "0:  abas y niño la.ér. un,.que poco,\n",
            "\n",
            " niño.\t\n",
            " no poco,te\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch    20  of     38. Loss: 0.21797917783260345.   Elapsed: 0:00:06.\n",
            "0:  llegaban con el sueño se\n",
            "no de\n",
            "que,que,de laérér, dormir\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch    30  of     38. Loss: 0.22844508290290833.   Elapsed: 0:00:09.\n",
            "0:  ayuda en. sueño. de\n",
            ", pory\n",
            "du mi a, cuna\t, lepara el, mi el\n",
            "du, el\n",
            "\n",
            "  Average training loss: 0.33\n",
            "  Training epoch took: 0:00:12\n",
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 0.24\n",
            "  Validation took: 0:00:00\n",
            "\n",
            "======== Epoch 6 / 40 ========\n",
            "Training...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch    10  of     38. Loss: 0.23346158862113953.   Elapsed: 0:00:03.\n",
            "0:  Girls demezo\n",
            " niño viene\n",
            " sequito,\n",
            "dume,,\n",
            " no\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch    20  of     38. Loss: 0.2497100979089737.   Elapsed: 0:00:06.\n",
            "0:  polvo.ññte que lleva: le mi cuna mi la.\n",
            "que elmi vienete. te\n",
            "de se coco,\n",
            "\t\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch    30  of     38. Loss: 0.1988544762134552.   Elapsed: 0:00:09.\n",
            "0: Los la\t\n",
            ", se las la se se\n",
            "du. a, niño\n",
            " tu\n",
            " madre. se\t\t\n",
            "\n",
            "  Average training loss: 0.30\n",
            "  Training epoch took: 0:00:12\n",
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 0.23\n",
            "  Validation took: 0:00:00\n",
            "\n",
            "======== Epoch 7 / 40 ========\n",
            "Training...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch    10  of     38. Loss: 0.17809653282165527.   Elapsed: 0:00:03.\n",
            "0: lu\" niño no el niño viene la el a niño\n",
            "\n",
            "Que,quito\n",
            "que la te.\n",
            " mi niño\t\t\n",
            "que\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch    20  of     38. Loss: 0.564190685749054.   Elapsed: 0:00:06.\n",
            "0:  reemp un\térme\n",
            "no.preme,que viene\n",
            "aquedu niño:\n",
            "que ni\n",
            "de, cuna\n",
            "po está\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch    30  of     38. Loss: 0.13663354516029358.   Elapsed: 0:00:09.\n",
            "0:  monumento, una niño niños le\n",
            " cabecera un\t\t\n",
            "no de…\n",
            "Y\t\n",
            "a este\t\t\n",
            "\n",
            "\n",
            "  Average training loss: 0.28\n",
            "  Training epoch took: 0:00:12\n",
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 0.21\n",
            "  Validation took: 0:00:00\n",
            "\n",
            "======== Epoch 8 / 40 ========\n",
            "Training...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch    10  of     38. Loss: 0.18259644508361816.   Elapsed: 0:00:03.\n",
            "0:  cosa la sueño no los viene\t\t\n",
            "que poco,\n",
            "sin tiene, de poco, este poco te,\n",
            "ni el\t\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch    20  of     38. Loss: 0.12280090153217316.   Elapsed: 0:00:06.\n",
            "0: mund en rico, viene niño\n",
            "Elñchote, mío\t\t\t\tquito\n",
            "y. chiquito\n",
            "duo niño ni,\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch    30  of     38. Loss: 0.18299706280231476.   Elapsed: 0:00:09.\n",
            "0: face la sierra\t\n",
            "cab niño\t\n",
            "sin niño ya,\n",
            "mi niño a lleva,jug\t\t\t\n",
            "\n",
            "  Average training loss: 0.27\n",
            "  Training epoch took: 0:00:12\n",
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 0.21\n",
            "  Validation took: 0:00:00\n",
            "\n",
            "======== Epoch 9 / 40 ========\n",
            "Training...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch    10  of     38. Loss: 0.1789911389350891.   Elapsed: 0:00:03.\n",
            "0:  denCon mi niño niño,\n",
            "que a coco, la viene el brazos la casa\n",
            "para le la la\t\n",
            "y a las\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch    20  of     38. Loss: 0.12740382552146912.   Elapsed: 0:00:06.\n",
            "0:  farmacéu la niño de brazos\t\n",
            "Y mucho a\t\t\n",
            "y poco bien\t\n",
            "que aquí,\t\n",
            "que gru dicen niño poco\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch    30  of     38. Loss: 0.1512448638677597.   Elapsed: 0:00:09.\n",
            "0:  fi\n",
            "a de la coco\t\t\n",
            "y,\t\t\t\n",
            "le aquí a una\t\n",
            "deba.\n",
            "\n",
            "  Average training loss: 0.25\n",
            "  Training epoch took: 0:00:12\n",
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 0.19\n",
            "  Validation took: 0:00:00\n",
            "\n",
            "======== Epoch 10 / 40 ========\n",
            "Training...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch    10  of     38. Loss: 0.16633999347686768.   Elapsed: 0:00:03.\n",
            "0:  mediterráneaDuérmete,ñito, niño,\n",
            "y al cocoermete,\n",
            "y tienecito,\t\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch    20  of     38. Loss: 1.4483463764190674.   Elapsed: 0:00:06.\n",
            "0:  Come, dormir a la dormir coco\n",
            "a está la n coco\n",
            "les co sus niños\n",
            "para lo co coco.\n",
            "y han poco a la\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch    30  of     38. Loss: 0.17742538452148438.   Elapsed: 0:00:09.\n",
            "0: calipsisLañito,\tito, ni no niño,\t\n",
            "y lomutete,\t\n",
            "de tu viene ni ya\n",
            "\n",
            "  Average training loss: 0.23\n",
            "  Training epoch took: 0:00:12\n",
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 0.18\n",
            "  Validation took: 0:00:00\n",
            "\n",
            "======== Epoch 11 / 40 ========\n",
            "Training...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch    10  of     38. Loss: 0.1786482185125351.   Elapsed: 0:00:03.\n",
            "0:  afectanDinalmete, de las mujeres\n",
            "de vez el niños\n",
            "le la casa a las compañera a la calle.\n",
            "le casa al contrario\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch    20  of     38. Loss: 0.12817206978797913.   Elapsed: 0:00:06.\n",
            "0:  afecta y\t\t\n",
            "para de Coco\n",
            "se lleva\n",
            "que le va la luna,\n",
            "en los casas\n",
            "Mi le lleva\n",
            "se le va\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch    30  of     38. Loss: 0.16366806626319885.   Elapsed: 0:00:09.\n",
            "0:  provis una niño, duerme\n",
            "no tu mueran ni si\t\n",
            "aqué le viene.\t\n",
            "y a la cabecera\n",
            "y\n",
            "\n",
            "  Average training loss: 0.21\n",
            "  Training epoch took: 0:00:12\n",
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 0.17\n",
            "  Validation took: 0:00:00\n",
            "\n",
            "======== Epoch 12 / 40 ========\n",
            "Training...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch    10  of     38. Loss: 0.13603368401527405.   Elapsed: 0:00:03.\n",
            "0:  Kur el sueño, niño no puede\n",
            "Al sueño,\n",
            "y le nacen cantando,\n",
            "para el sueño le lleva.\n",
            "y\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch    20  of     38. Loss: 0.3356892466545105.   Elapsed: 0:00:06.\n",
            "0:  debutar que niño le crecen,\n",
            "que viene a la sierra\t\t\n",
            "devolando a que habita\t\t\t\t\n",
            "que\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch    30  of     38. Loss: 0.11241262406110764.   Elapsed: 0:00:10.\n",
            "0:  Gib y niño pequeñito no tiene jacazo,\t\n",
            "que viene el coano se tiene ti.\n",
            "por vez\n",
            "\n",
            "  Average training loss: 0.18\n",
            "  Training epoch took: 0:00:12\n",
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 0.18\n",
            "  Validation took: 0:00:00\n",
            "\n",
            "======== Epoch 13 / 40 ========\n",
            "Training...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch    10  of     38. Loss: 0.11150544136762619.   Elapsed: 0:00:03.\n",
            "0:  Jurado de Dios mi niño,\n",
            "qué viene la reina,\n",
            "Que está comer.\t\n",
            "y le tiene el sol.\n",
            "Si\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch    20  of     38. Loss: 0.3415808379650116.   Elapsed: 0:00:06.\n",
            "0: fro el coco\t\n",
            "Al sueño,\t\n",
            "no tiene llorar,\t\t\n",
            "que viene el coquito y\t\n",
            "duérmete y\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch    30  of     38. Loss: 0.16318558156490326.   Elapsed: 0:00:10.\n",
            "0: \u0018Duérmete, mi hijito,\t\n",
            "Al sueño de grutas,\n",
            "y se lleva el coco:\n",
            "\n",
            "\n",
            "  Average training loss: 0.16\n",
            "  Training epoch took: 0:00:12\n",
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 0.17\n",
            "  Validation took: 0:00:00\n",
            "\n",
            "======== Epoch 14 / 40 ========\n",
            "Training...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch    10  of     38. Loss: 0.0766833946108818.   Elapsed: 0:00:03.\n",
            "0:  cano más mujeres, niño no durmiera,\n",
            "que viene el coco\n",
            "montado a cantar\n",
            "y se durmió.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch    20  of     38. Loss: 0.05097780004143715.   Elapsed: 0:00:06.\n",
            "0:  fúnDuérmete, niñito mío,\t\n",
            "preguntando y milano,\t\t\n",
            "para que aquí está dormir\t\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch    30  of     38. Loss: 0.08969077467918396.   Elapsed: 0:00:10.\n",
            "0:  1930Duérmete, niño,\t\t\n",
            "Venga una cuna de cuna de cuna\n",
            "ni mucho.\t\n",
            "para\n",
            "\n",
            "  Average training loss: 0.13\n",
            "  Training epoch took: 0:00:12\n",
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 0.17\n",
            "  Validation took: 0:00:00\n",
            "\n",
            "======== Epoch 15 / 40 ========\n",
            "Training...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch    10  of     38. Loss: 0.16595320403575897.   Elapsed: 0:00:03.\n",
            "0: inuDuermete,\t\t\n",
            "Duérmete, mi bien.\t\t\t\n",
            "que viene el gavilán\n",
            "no le\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch    20  of     38. Loss: 0.08335240185260773.   Elapsed: 0:00:06.\n",
            "0:  téDuérmete, niño,\n",
            "duérmete,\n",
            "qué será el viento.\n",
            "duérmete y\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch    30  of     38. Loss: 0.05307620391249657.   Elapsed: 0:00:10.\n",
            "0:  puntuación las madres de yerba,\n",
            "que el brujo de la estrella\n",
            "que aquí está la cabeza.\n",
            "que te dorm\n",
            "\n",
            "  Average training loss: 0.12\n",
            "  Training epoch took: 0:00:12\n",
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 0.17\n",
            "  Validation took: 0:00:00\n",
            "\n",
            "======== Epoch 16 / 40 ========\n",
            "Training...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch    10  of     38. Loss: 0.0893954187631607.   Elapsed: 0:00:03.\n",
            "0:  SoloDuérmete, niño chiquito,\t\n",
            "que ahí viene el coco\t\n",
            "poquito tienes.\n",
            "Este niño…… niñ\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch    20  of     38. Loss: 0.025074301287531853.   Elapsed: 0:00:06.\n",
            "0:  lenguDúerme, niño,\t\t\n",
            "que viene el trigo\t\n",
            "que viene el trigo\n",
            "le doy a la luna\n",
            "lo\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch    30  of     38. Loss: 0.06248408928513527.   Elapsed: 0:00:10.\n",
            "0:  NuestraDuérmete, niño,\t\n",
            "duérmete,\t\t\n",
            "que viene el coco;\n",
            "que tengas miedo,\n",
            "\n",
            "\n",
            "  Average training loss: 0.10\n",
            "  Training epoch took: 0:00:12\n",
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 0.17\n",
            "  Validation took: 0:00:00\n",
            "\n",
            "======== Epoch 17 / 40 ========\n",
            "Training...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch    10  of     38. Loss: 0.06278975307941437.   Elapsed: 0:00:03.\n",
            "0: oldsLas mujeres de la sierra\n",
            "El coquito\n",
            "vendrá por Dios,\n",
            "lo echó.\n",
            "y le haga una cuna\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch    20  of     38. Loss: 0.03161592036485672.   Elapsed: 0:00:06.\n",
            "0:  vacíoEn la mar de la mar de cuna\n",
            "que quiere el techo de cuna.\t\n",
            "y se durmió.\t\t\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch    30  of     38. Loss: 0.2635646164417267.   Elapsed: 0:00:10.\n",
            "0:  piDuérmete, niño chico,\n",
            "que viene el coco,\n",
            "y se lleva a los niños\n",
            "quién es carpintero\n",
            "y se ha\n",
            "\n",
            "  Average training loss: 0.08\n",
            "  Training epoch took: 0:00:12\n",
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 0.17\n",
            "  Validation took: 0:00:00\n",
            "\n",
            "======== Epoch 18 / 40 ========\n",
            "Training...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch    10  of     38. Loss: 0.05777644366025925.   Elapsed: 0:00:03.\n",
            "0:  aproximadamenteEste niño no puede dormir\n",
            "que viene el brujo.\n",
            "Que viene el sol.\n",
            "deja.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch    20  of     38. Loss: 0.054831139743328094.   Elapsed: 0:00:06.\n",
            "0:  PPDuérmete, niño chiquito\n",
            "duerme sin pena,\n",
            "me sin pena,\n",
            "que si este niño chiquito\n",
            "mon\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch    30  of     38. Loss: 0.04714830964803696.   Elapsed: 0:00:10.\n",
            "0:  ÉDuérmete, niño,\n",
            "duérmete,\n",
            "Que viene el viento.\n",
            "cabeza de mecer.\n",
            "volando,\n",
            "\n",
            "  Average training loss: 0.07\n",
            "  Training epoch took: 0:00:12\n",
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 0.17\n",
            "  Validation took: 0:00:00\n",
            "\n",
            "======== Epoch 19 / 40 ========\n",
            "Training...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch    10  of     38. Loss: 0.0415349006652832.   Elapsed: 0:00:03.\n",
            "0: Tiene se la jaca con alas\n",
            "que te ha de nenes\n",
            "preguntando por cabecera en casa.\n",
            "preguntando\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch    20  of     38. Loss: 0.27287769317626953.   Elapsed: 0:00:06.\n",
            "0:  expulsóDuérmete, guagüita\t\n",
            "que viene el coco\n",
            "no quiere dormir los chiquillos\n",
            "porque al pie de la calle.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch    30  of     38. Loss: 0.04495071619749069.   Elapsed: 0:00:10.\n",
            "0:  mínimaDuérmete, niño chiquito,\n",
            "duérmete, en la casa;\n",
            "que viene el trancazo.\n",
            "Y\n",
            "\n",
            "  Average training loss: 0.07\n",
            "  Training epoch took: 0:00:12\n",
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 0.17\n",
            "  Validation took: 0:00:00\n",
            "\n",
            "======== Epoch 20 / 40 ========\n",
            "Training...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch    10  of     38. Loss: 0.04921691119670868.   Elapsed: 0:00:03.\n",
            "0:  conceptual a la cuna\n",
            "Que viene el coco\n",
            "Que esta voz apura,\n",
            "Que viene el cura\n",
            "Asusta poco.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch    20  of     38. Loss: 0.3020934462547302.   Elapsed: 0:00:06.\n",
            "0:  Moreno y le crecen\t\n",
            "y considero,\t\n",
            "lo parió una gitana,\t\n",
            "un pedacito de ti,\t\n",
            "para no\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch    30  of     38. Loss: 0.047179002314805984.   Elapsed: 0:00:10.\n",
            "0:  presideDuérmete, mi negrazo,\n",
            "duérmete mi negrazo,\n",
            "lo echó a la calle.\n",
            "Su padre es\n",
            "\n",
            "  Average training loss: 0.06\n",
            "  Training epoch took: 0:00:12\n",
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 0.17\n",
            "  Validation took: 0:00:00\n",
            "\n",
            "======== Epoch 21 / 40 ========\n",
            "Training...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch    10  of     38. Loss: 0.03317577391862869.   Elapsed: 0:00:03.\n",
            "0:  totalCon un traje rico\n",
            "lo echó a dormir a los niños\n",
            "que a la calle.\n",
            "Si el caso a los niños\n",
            "Que viene el\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch    20  of     38. Loss: 0.03785642981529236.   Elapsed: 0:00:06.\n",
            "0:  propulsión la sierra,\n",
            "Que esta voz a sus niños\n",
            "Que esta voz a su casa.\t\n",
            "Al sueño le haga una nana\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch    30  of     38. Loss: 0.023612700402736664.   Elapsed: 0:00:10.\n",
            "0:  IsaacDuérmete, niñito mío,\n",
            "duérmete,\n",
            "duérmete,\n",
            "duérmete,\n",
            "\n",
            "\n",
            "  Average training loss: 0.06\n",
            "  Training epoch took: 0:00:12\n",
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 0.16\n",
            "  Validation took: 0:00:00\n",
            "\n",
            "======== Epoch 22 / 40 ========\n",
            "Training...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch    10  of     38. Loss: 0.03306236490607262.   Elapsed: 0:00:03.\n",
            "0: useppeDuérmete, niño,\n",
            "que tengo que hacer,\n",
            "que tengo que hacer,\n",
            "si este niño… mi prenda.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch    20  of     38. Loss: 0.03488972783088684.   Elapsed: 0:00:06.\n",
            "0:  documen de la mar, si no se durmiera,\t\n",
            "que viene el viento.\t\t\n",
            "Ya en el caso de pan.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch    30  of     38. Loss: 0.02656174637377262.   Elapsed: 0:00:10.\n",
            "0:  fábricas se vino llevó la Virgen del cielo\n",
            "yo le crecen\t\n",
            "no has nacido.\t\t\n",
            "Márchate despacito,\t\t\n",
            "\n",
            "  Average training loss: 0.05\n",
            "  Training epoch took: 0:00:12\n",
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 0.18\n",
            "  Validation took: 0:00:00\n",
            "\n",
            "======== Epoch 23 / 40 ========\n",
            "Training...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch    10  of     38. Loss: 0.06356164813041687.   Elapsed: 0:00:03.\n",
            "0:  hoyDuérmete, niñito,\t\t\n",
            "si no te dormís,\t\n",
            "le va perdiendo el miedo\t\n",
            "poquito\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch    20  of     38. Loss: 0.027395714074373245.   Elapsed: 0:00:06.\n",
            "0:  NashCon un traje rico\t\t\n",
            "y se lleva a los niños\t\n",
            "que le nacen azules gacelas,\t\t\n",
            "que viene la\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch    30  of     38. Loss: 0.061021339148283005.   Elapsed: 0:00:10.\n",
            "0:  64Duérmete, niño chico,\n",
            "duérmete, mi bien;\n",
            "que aquí está la cunita\n",
            "que te ha de\n",
            "\n",
            "  Average training loss: 0.04\n",
            "  Training epoch took: 0:00:12\n",
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 0.18\n",
            "  Validation took: 0:00:00\n",
            "\n",
            "======== Epoch 24 / 40 ========\n",
            "Training...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch    10  of     38. Loss: 0.03540550172328949.   Elapsed: 0:00:03.\n",
            "0: berry, niño tiene sueño,\n",
            "para dormir los chiquillos\n",
            "no tiene cama.\n",
            "que duermen poco.\t\t\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch    20  of     38. Loss: 0.014713844284415245.   Elapsed: 0:00:06.\n",
            "0:  ciclismoDuérmete, niñito,\t\t\n",
            "duérmete, mi bien;\t\t\n",
            "que viene el brujo\t\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch    30  of     38. Loss: 0.016773343086242676.   Elapsed: 0:00:10.\n",
            "0: FoDuérmete, niño chico,\n",
            "duérmete, niño de cuna,\n",
            "gruñan los perros.\n",
            "que duermen poco\n",
            "\n",
            "  Average training loss: 0.03\n",
            "  Training epoch took: 0:00:12\n",
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 0.17\n",
            "  Validation took: 0:00:00\n",
            "\n",
            "======== Epoch 25 / 40 ========\n",
            "Training...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch    10  of     38. Loss: 0.024383898824453354.   Elapsed: 0:00:03.\n",
            "0:  sucursalDuérmete, vida mía,\n",
            "duérmete y no llores más,\n",
            "que está la cunita\n",
            "y te ha\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch    20  of     38. Loss: 0.023364577442407608.   Elapsed: 0:00:06.\n",
            "0:  agresivaDuérmete, mi niño,\n",
            "duérmete sin pena,\n",
            "que viene la cunita\n",
            "y te comerá.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch    30  of     38. Loss: 0.026034386828541756.   Elapsed: 0:00:10.\n",
            "0:  sediCon un traje rico\n",
            "cabellos de yerba.\n",
            "que el coco;\n",
            "que tengas miedo,\n",
            "ni mucho ni poco.\n",
            "\n",
            "  Average training loss: 0.03\n",
            "  Training epoch took: 0:00:12\n",
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 0.18\n",
            "  Validation took: 0:00:00\n",
            "\n",
            "======== Epoch 26 / 40 ========\n",
            "Training...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch    10  of     38. Loss: 0.018250228837132454.   Elapsed: 0:00:03.\n",
            "0:  cenaDuérmete, niño,\t\t\n",
            "duérmete, mi bien;\t\t\n",
            "que aquí está la cunita\t\t\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch    20  of     38. Loss: 0.02992088906466961.   Elapsed: 0:00:06.\n",
            "0:  presentadoDuérmete mi negrazo,\t\t\n",
            "duérmete, mi bien;\t\t\n",
            "que aquí está la cunita\t\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch    30  of     38. Loss: 0.06555982679128647.   Elapsed: 0:00:10.\n",
            "0:  paleo las mujeres de la sierra\n",
            "para dormir a sus niños.\n",
            "¡Vete, milano! que al niño\n",
            "le estoy cantando una n\n",
            "\n",
            "  Average training loss: 0.03\n",
            "  Training epoch took: 0:00:12\n",
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 0.18\n",
            "  Validation took: 0:00:00\n",
            "\n",
            "======== Epoch 27 / 40 ========\n",
            "Training...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch    10  of     38. Loss: 0.13746517896652222.   Elapsed: 0:00:03.\n",
            "0:  elloDuérmete, guagüita\t\t\n",
            "duérmete y no llores más,\t\t\n",
            "aunque silben los aires\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch    20  of     38. Loss: 0.024640081450343132.   Elapsed: 0:00:06.\n",
            "0:  simEste galapaguito no tiene mare.\n",
            "lo parió una gitana,\n",
            "lo echó a la calle.\n",
            "Este niño chiquito\n",
            "no\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch    30  of     38. Loss: 0.01225416548550129.   Elapsed: 0:00:10.\n",
            "0:  Soph se durmiera,\t\t\n",
            "que quiere el coco,\t\t\n",
            "le va perdiendo el miedo\t\n",
            "poquito a poco.\n",
            "\n",
            "  Average training loss: 0.02\n",
            "  Training epoch took: 0:00:12\n",
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 0.18\n",
            "  Validation took: 0:00:00\n",
            "\n",
            "======== Epoch 28 / 40 ========\n",
            "Training...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch    10  of     38. Loss: 0.009696375578641891.   Elapsed: 0:00:03.\n",
            "0:  MexicDuérmete, mi niño,\n",
            "duérmete sin miedo,\n",
            "aunque silben los aires,\n",
            "gruñan los perros.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch    20  of     38. Loss: 0.018254244700074196.   Elapsed: 0:00:06.\n",
            "0: ºCDúermete, niñito,\t\t\n",
            "cabeza de ayote;\t\t\n",
            "si no te dormís,\t\t\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch    30  of     38. Loss: 0.03334523364901543.   Elapsed: 0:00:10.\n",
            "0: JuanVete ya, lobo malo,\n",
            "no se despierte.\t\n",
            "Al sueño le nacen azules gacelas,\t\t\n",
            "\n",
            "  Average training loss: 0.02\n",
            "  Training epoch took: 0:00:12\n",
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 0.18\n",
            "  Validation took: 0:00:00\n",
            "\n",
            "======== Epoch 29 / 40 ========\n",
            "Training...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch    10  of     38. Loss: 0.02908271551132202.   Elapsed: 0:00:03.\n",
            "0:  llevóDuérmete, niño mío,\n",
            "que tu madre no está en casa;\n",
            "que se la llevó la Virgen\n",
            "de compañera a su\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch    20  of     38. Loss: 0.017919478937983513.   Elapsed: 0:00:06.\n",
            "0:  suizos.\t\n",
            "y su hijito feo,\t\t\n",
            "la loba, la loba,\t\t\n",
            "vendrá\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch    30  of     38. Loss: 0.013643993064761162.   Elapsed: 0:00:10.\n",
            "0:  TamEste galapaguito no tiene mare.\n",
            "lo parió una gitana,\n",
            "lo echó a la calle.\n",
            "Este niño chiquito\n",
            "Este\n",
            "\n",
            "  Average training loss: 0.02\n",
            "  Training epoch took: 0:00:12\n",
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 0.18\n",
            "  Validation took: 0:00:00\n",
            "\n",
            "======== Epoch 30 / 40 ========\n",
            "Training...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch    10  of     38. Loss: 0.07286306470632553.   Elapsed: 0:00:03.\n",
            "0:  HopkinsEste niño tiene sueño,\t\t\n",
            "no tiene cama ni cuna.\t\t\n",
            "A su padre carpintero\t\t\n",
            "le diremos le haga\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch    20  of     38. Loss: 0.016072824597358704.   Elapsed: 0:00:06.\n",
            "0: iblioEste niño tiene sueño,\t\t\n",
            "no tiene cama ni cuna.\t\t\n",
            "A su padre carpintero\t\t\n",
            "le diremos le haga\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch    30  of     38. Loss: 0.011044599115848541.   Elapsed: 0:00:10.\n",
            "0:  FemenDuérmete, niño chiquito,\t\n",
            "duérmete y no llores más,\t\t\n",
            "que se la cunita\n",
            "\n",
            "  Average training loss: 0.02\n",
            "  Training epoch took: 0:00:12\n",
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 0.18\n",
            "  Validation took: 0:00:00\n",
            "\n",
            "======== Epoch 31 / 40 ========\n",
            "Training...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch    10  of     38. Loss: 0.009602007456123829.   Elapsed: 0:00:03.\n",
            "0:  arzobispoEste niño no puede dormir.\n",
            "El coquito no le deja,\n",
            "que le tiene agarradito\n",
            "de los pies a la cabeza.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch    20  of     38. Loss: 0.01855579949915409.   Elapsed: 0:00:06.\n",
            "0: soviaDúermete, niñito,\t\t\n",
            "cabeza de ayote;\t\t\n",
            "si no te dormís,\t\t\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch    30  of     38. Loss: 0.01680821180343628.   Elapsed: 0:00:10.\n",
            "0:  valoraciónA la mar, si no duermes,\t\t\n",
            "que viene el viento.\t\n",
            "Ya en las grutas marinas\t\n",
            "\n",
            "\n",
            "  Average training loss: 0.02\n",
            "  Training epoch took: 0:00:12\n",
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 0.19\n",
            "  Validation took: 0:00:00\n",
            "\n",
            "======== Epoch 32 / 40 ========\n",
            "Training...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch    10  of     38. Loss: 0.012686608359217644.   Elapsed: 0:00:03.\n",
            "0:  ChiloéEste niño tiene sueño,\t\n",
            "no tiene cama ni cuna.\t\t\n",
            "A su padre carpintero\t\n",
            "le diremos le haga una.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch    20  of     38. Loss: 0.011327101849019527.   Elapsed: 0:00:06.\n",
            "0:  OrtizDuérmete mi negrazo,\t\t\n",
            "que viene el coco,\t\t\n",
            "y se lleva a los nenes\t\n",
            "que\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch    30  of     38. Loss: 0.010652289725840092.   Elapsed: 0:00:10.\n",
            "0: lóDuérmete, niñito,\t\t\n",
            "duérmete, por Dios,\t\t\n",
            "si no viene el brujo\n",
            "\n",
            "  Average training loss: 0.02\n",
            "  Training epoch took: 0:00:12\n",
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 0.19\n",
            "  Validation took: 0:00:00\n",
            "\n",
            "======== Epoch 33 / 40 ========\n",
            "Training...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch    10  of     38. Loss: 0.007933475077152252.   Elapsed: 0:00:03.\n",
            "0:  tall\n",
            "Que viene el coco;\n",
            "Que esta voz a este niño,\n",
            "Asusta poco.\n",
            "Si el caso apura,\n",
            "Le dicen\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch    20  of     38. Loss: 0.011670873500406742.   Elapsed: 0:00:07.\n",
            "0:  trajoLas mujeres de la sierra,\t\t\n",
            "para dormir a sus niños,\t\t\n",
            "en vez de llamar al coco\t\t\t\n",
            "les\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch    30  of     38. Loss: 0.010136229917407036.   Elapsed: 0:00:10.\n",
            "0: ípDuérmete, niño de cuna,\n",
            "duérmete ya\n",
            "que aquí está la cunita\n",
            "que te ha de mecer\n",
            "\n",
            "  Average training loss: 0.01\n",
            "  Training epoch took: 0:00:13\n",
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 0.19\n",
            "  Validation took: 0:00:00\n",
            "\n",
            "======== Epoch 34 / 40 ========\n",
            "Training...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch    10  of     38. Loss: 0.019570015370845795.   Elapsed: 0:00:03.\n",
            "0:  vacaDuérmete, niño chico,\n",
            "duérmete sin miedo,\n",
            "aunque silben los aires,\n",
            "gruñan los perros.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch    20  of     38. Loss: 0.009321775287389755.   Elapsed: 0:00:06.\n",
            "0: yerDuérmete, niñito mío,\n",
            "que tu madre no está en casa;\n",
            "que se la llevó la Virgen\n",
            "de compañera\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch    30  of     38. Loss: 0.008232462219893932.   Elapsed: 0:00:10.\n",
            "0:  tecnológicosDuérmete, mi niño chico,\n",
            "duérmete, niño de amor,\n",
            "que a los pies tienes la luna\n",
            "y\n",
            "\n",
            "  Average training loss: 0.01\n",
            "  Training epoch took: 0:00:12\n",
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 0.19\n",
            "  Validation took: 0:00:00\n",
            "\n",
            "======== Epoch 35 / 40 ========\n",
            "Training...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch    10  of     38. Loss: 0.01248258352279663.   Elapsed: 0:00:03.\n",
            "0: ársDuérmete, niño de cuna,\n",
            "duérmete, niño de amor,\n",
            "que a los pies tienes la luna\n",
            "y\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch    20  of     38. Loss: 0.015604635700583458.   Elapsed: 0:00:06.\n",
            "0:  movilizaciónDuérmete, niñito,\t\t\n",
            "duérmete, por Dios,\t\t\n",
            "que aquí está la cunita\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch    30  of     38. Loss: 0.0169672854244709.   Elapsed: 0:00:10.\n",
            "0:  kmDuérmete, niño,\n",
            "duérmete, mi bien;\n",
            "que aquí está la cunita\n",
            "que te ha de m\n",
            "\n",
            "  Average training loss: 0.01\n",
            "  Training epoch took: 0:00:12\n",
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 0.19\n",
            "  Validation took: 0:00:00\n",
            "\n",
            "======== Epoch 36 / 40 ========\n",
            "Training...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch    10  of     38. Loss: 0.008184398524463177.   Elapsed: 0:00:03.\n",
            "0:  ChelseaDuérmete, niño chiquito,\t\t\n",
            "duérmete y no llores más,\t\t\n",
            "no se irán los\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch    20  of     38. Loss: 0.011381630785763264.   Elapsed: 0:00:06.\n",
            "0: cristiDuérmete, niño,\n",
            "duérmete ya\n",
            "que viene el coco\n",
            "y te comerá.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch    30  of     38. Loss: 0.008000083267688751.   Elapsed: 0:00:10.\n",
            "0:  destinoDuérmete, guagüita,\t\t\n",
            "duérmete y no llores más,\t\t\n",
            "que se irán los\n",
            "\n",
            "  Average training loss: 0.01\n",
            "  Training epoch took: 0:00:12\n",
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 0.19\n",
            "  Validation took: 0:00:00\n",
            "\n",
            "======== Epoch 37 / 40 ========\n",
            "Training...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch    10  of     38. Loss: 0.028063494712114334.   Elapsed: 0:00:03.\n",
            "0:  divididosDuérmete, vida mía,\t\n",
            "duérmete sin miedo,\t\t\n",
            "si no viene el brujo\t\n",
            "y\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch    20  of     38. Loss: 0.00894069392234087.   Elapsed: 0:00:06.\n",
            "0:  enclaveDúermete, mi bien;\n",
            "que aquí está la cunita\n",
            "que te ha de mecer.\t\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch    30  of     38. Loss: 0.03491850569844246.   Elapsed: 0:00:10.\n",
            "0:  vaporDuérmete mi negrazo,\t\t\n",
            "cara de pambazo,\t\t\n",
            "que si no se duerme\t\t\n",
            "le\n",
            "\n",
            "  Average training loss: 0.01\n",
            "  Training epoch took: 0:00:12\n",
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 0.19\n",
            "  Validation took: 0:00:00\n",
            "\n",
            "======== Epoch 38 / 40 ========\n",
            "Training...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch    10  of     38. Loss: 0.010461279191076756.   Elapsed: 0:00:03.\n",
            "0:  debaDuérmete, niñito mío,\n",
            "que tu madre no está en casa;\n",
            "que se la llevó la Virgen\n",
            "de compañera\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch    20  of     38. Loss: 0.033336058259010315.   Elapsed: 0:00:06.\n",
            "0: quet en los brazos te tengo\t\t\n",
            "y considero\t\t\n",
            "qué será de ti, niño,\t\t\n",
            "si yo me muero\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch    30  of     38. Loss: 0.01820303127169609.   Elapsed: 0:00:10.\n",
            "0:  mineralesDúermete, mi bien;\n",
            "que aquí está la cunita\n",
            "que te ha de mecer.\n",
            "\n",
            "  Average training loss: 0.01\n",
            "  Training epoch took: 0:00:12\n",
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 0.19\n",
            "  Validation took: 0:00:00\n",
            "\n",
            "======== Epoch 39 / 40 ========\n",
            "Training...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch    10  of     38. Loss: 0.0208473838865757.   Elapsed: 0:00:03.\n",
            "0: mirDuérmete, niñito,\t\t\n",
            "duérmete y no llores más,\t\t\n",
            "que se irán los\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch    20  of     38. Loss: 0.017104851081967354.   Elapsed: 0:00:06.\n",
            "0: omalDuérmete, niño,\n",
            "duérmete, mi bien;\n",
            "que aquí está la cunita\n",
            "que te ha de m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch    30  of     38. Loss: 0.009394308552145958.   Elapsed: 0:00:10.\n",
            "0:  claridadCon un traje rico\t\t\n",
            "y su hijito feo,\t\t\n",
            "la loba, la loba,\t\t\n",
            "\n",
            "\n",
            "  Average training loss: 0.01\n",
            "  Training epoch took: 0:00:12\n",
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 0.19\n",
            "  Validation took: 0:00:00\n",
            "\n",
            "======== Epoch 40 / 40 ========\n",
            "Training...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch    10  of     38. Loss: 0.029529031366109848.   Elapsed: 0:00:03.\n",
            "0:  ClaseDuérmete, niño chico,\n",
            "duérmete ya\n",
            "que aquí está la cunita\n",
            "que te ha de mecer.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch    20  of     38. Loss: 0.006891859695315361.   Elapsed: 0:00:06.\n",
            "0:  crédiDuérmete, vida mía,\n",
            "duerme sin pena,\n",
            "porque al pie de la cuna\n",
            "tu madre vela.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch    30  of     38. Loss: 0.01500753778964281.   Elapsed: 0:00:10.\n",
            "0:  congreCon decirle a mi niño\t\n",
            "que viene el coco\t\n",
            "y se lleva a los niños\t\t\n",
            "que duermen poco.\n",
            "\n",
            "  Average training loss: 0.01\n",
            "  Training epoch took: 0:00:12\n",
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 0.19\n",
            "  Validation took: 0:00:00\n",
            "\n",
            "Training complete!\n",
            "Total training took 0:08:19 (h:mm:ss)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U2zVVst0nRFk"
      },
      "source": [
        "### Save fine-tuned model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Of9EPidCnoaD"
      },
      "source": [
        "Mount google drive and save the model in a specific folder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kCWAAxdWnViG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5df019d-a5f4-4646-d9f0-a17802536628"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vGNJ2EjVrlnK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f51b82f-5fc9-4b27-9000-5f205744b8d3"
      },
      "source": [
        "%cd '/content/gdrive/MyDrive/AI song contest/'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/MyDrive/AI song contest\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UlpUf4xtf8wH"
      },
      "source": [
        "model.eval() # ensure the model is 'frozen'\n",
        "torch.save(model.state_dict(), 'Models/model_nana_v3.pt')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}